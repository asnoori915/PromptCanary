"""
DATABASE MODELS - SQLAlchemy ORM models for the entire system

This file defines all the database tables and their relationships.
The models represent the core entities in the prompt evaluation system:

Core Entities:
- Prompt: The main prompt text being evaluated
- Response: LLM responses to prompts
- Evaluation: Scores and analysis of prompt/response pairs
- Suggestion: Improved versions of prompts
- Feedback: Human ratings and comments

Versioning System:
- PromptVersion: Different versions of the same prompt
- PromptRelease: Manages active vs canary versions
- RollbackEvent: Audit trail of rollback decisions

All models use proper foreign keys, cascading deletes, and relationships.
"""

from sqlalchemy import Column, Integer, Text, DateTime, ForeignKey, String, Float, Boolean
from sqlalchemy.sql import func
from sqlalchemy.orm import relationship
from app.db import Base


class Prompt(Base):
    """
    Core prompt entity - the main text being evaluated and improved.
    
    This is the central entity that everything else relates to.
    A prompt can have multiple versions, responses, evaluations, suggestions, and feedback.
    """
    __tablename__ = "prompts"
    id = Column(Integer, primary_key=True, index=True)
    text = Column(Text, nullable=False)  # The actual prompt text
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    # Relationships - all related data gets deleted when prompt is deleted
    responses   = relationship("Response", back_populates="prompt", cascade="all, delete-orphan")
    evaluations = relationship("Evaluation", back_populates="prompt", cascade="all, delete-orphan")
    suggestions = relationship("Suggestion", back_populates="prompt", cascade="all, delete-orphan")
    feedback    = relationship("Feedback", back_populates="prompt", cascade="all, delete-orphan")


class Response(Base):
    """
    LLM response to a prompt - stores the actual output and metadata.
    
    This captures what the LLM returned, along with performance metrics
    like latency and token usage for analysis.
    """
    __tablename__ = "responses"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    model_name = Column(String(64))  # Which LLM generated this response
    content = Column(Text, nullable=False)  # The actual response text
    latency_ms = Column(Integer)  # How long it took to generate
    input_tokens = Column(Integer)  # Tokens used for input
    output_tokens = Column(Integer)  # Tokens generated in output
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    prompt = relationship("Prompt", back_populates="responses")
    evaluations = relationship("Evaluation", back_populates="response", cascade="all, delete-orphan")


class Evaluation(Base):
    """
    Evaluation scores for a prompt/response pair - the core scoring data.
    
    This stores both heuristic scores (fast, rule-based) and LLM scores
    (slower, more sophisticated). The is_canary flag tracks whether this
    evaluation was for a canary version or active version.
    """
    __tablename__ = "evaluations"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    response_id = Column(Integer, ForeignKey("responses.id", ondelete="SET NULL"))
    
    # Scoring dimensions (0-1 scale)
    clarity_score = Column(Float)  # How clear/unambiguous the prompt is
    length_score = Column(Float)   # Optimal length scoring
    toxicity_score = Column(Float) # Content safety scoring
    overall_score = Column(Float)  # Combined/weighted overall score
    notes = Column(Text)  # LLM-generated improvement suggestions
    
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    is_canary = Column(Boolean, nullable=False, server_default="0")  # Was this canary version?

    prompt = relationship("Prompt", back_populates="evaluations")
    response = relationship("Response", back_populates="evaluations")


class Suggestion(Base):
    """
    Improved version of a prompt - generated by the optimization system.
    
    This stores alternative versions of prompts that could potentially
    perform better. These become candidates for canary releases.
    """
    __tablename__ = "suggestions"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    suggested_text = Column(Text, nullable=False)  # The improved prompt text
    rationale = Column(Text)  # Why this version is better
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    prompt = relationship("Prompt", back_populates="suggestions")


class Feedback(Base):
    """
    Human feedback on prompts and responses - the "human in the loop" data.
    
    This captures human ratings and comments to validate and improve
    the automated evaluation system.
    """
    __tablename__ = "feedback"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    response_id = Column(Integer, ForeignKey("responses.id", ondelete="SET NULL"))
    rating = Column(Integer)  # Human rating 1-5
    comment = Column(Text)  # Optional human comment
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    prompt = relationship("Prompt", back_populates="feedback")


class PromptVersion(Base):
    """
    Versioned prompt text - enables canary releases and rollbacks.
    
    This allows the same prompt to have multiple versions over time.
    Each version can be tested independently and compared for performance.
    """
    __tablename__ = "prompt_versions"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    version = Column(Integer, nullable=False)  # Version number (1, 2, 3, etc.)
    text = Column(Text, nullable=False)  # The actual prompt text for this version
    is_active = Column(Boolean, nullable=False, server_default="0")  # Is this the current active version?
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    prompt = relationship("Prompt", backref="versions")


class PromptRelease(Base):
    """
    Release management - controls active vs canary versions and traffic splitting.
    
    This is the "traffic controller" that manages which version gets what percentage
    of traffic. It enables canary deployments and rollbacks.
    """
    __tablename__ = "prompt_releases"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    active_version_id = Column(Integer, ForeignKey("prompt_versions.id", ondelete="SET NULL"))
    canary_version_id = Column(Integer, ForeignKey("prompt_versions.id", ondelete="SET NULL"))
    canary_percent = Column(Integer, nullable=False, server_default="0")  # 0-100% traffic to canary
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), server_default=func.now())

    prompt = relationship("Prompt")
    active_version = relationship("PromptVersion", foreign_keys=[active_version_id])
    canary_version = relationship("PromptVersion", foreign_keys=[canary_version_id])


class RollbackEvent(Base):
    """
    Audit trail of rollback decisions - tracks when and why rollbacks happened.
    
    This provides transparency and debugging capability for the canary system.
    Every rollback (manual or automatic) creates a record here.
    """
    __tablename__ = "rollback_events"
    id = Column(Integer, primary_key=True, index=True)
    prompt_id = Column(Integer, ForeignKey("prompts.id", ondelete="CASCADE"), nullable=False)
    from_version_id = Column(Integer, ForeignKey("prompt_versions.id", ondelete="SET NULL"))
    to_version_id = Column(Integer, ForeignKey("prompt_versions.id", ondelete="SET NULL"))
    reason = Column(Text)  # Why the rollback happened
    created_at = Column(DateTime(timezone=True), server_default=func.now())

    prompt = relationship("Prompt")
    from_version = relationship("PromptVersion", foreign_keys=[from_version_id])
    to_version = relationship("PromptVersion", foreign_keys=[to_version_id])
